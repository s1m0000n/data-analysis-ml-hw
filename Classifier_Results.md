# Тестирование методов классификации

## Выборка

В качестве датасета был выбраны русские твиты с метками об их окрашенности: https://study.mokoron.com/

Для каждого твита: positive/negative

Следовательно решалась задача классификации эмоционально окрашенных текстов

## Методы

1. Метод из лекции - SVM
2. Выбранный метод не из лекции - нейронная сеть с одиним линейным слоем

Признаки для первого метода - RuBERT от DeepPavlov, генерирующий вектора для последовательности. Вместо обычного SVM использовался Linear SVM, потому что SVM слишком медленный для такого датасета.

Во втором методе был такой же RuBERT, но он дообучался вместе с линейным полносвязным слоем одну эпоху.

Ссылка на Colab - первый метод: https://colab.research.google.com/drive/1YNBVBHDsTRsBFqFmrBNXO7U5ui4nuCbC?usp=sharing

Ссылка на Colab - второй метод: https://colab.research.google.com/drive/1p8El-WsGPZ7f60Z3984u2v0QJzTSM1UT?usp=sharing

Перед запуском убедитесь, что используете GPU, поскольку даже на Tesla P100 у меня обучалось 20 минут на втором методе. Меньше по времени, но всё равно долго для первого метода.

### Более подробно о методе 2

Используется предобученный русскоязычный BERT с 12-ю головами внутреннего внимания, дальше - полносвязный линейный слой. Внутренние подробности реализации в библиотеке transformers от Hugging Face не узнавал, так как это было не так важно для тестирования.

В качестве метода оптимизации модели был использовал Adam.

Данная модель хорошо себя показывает на многих задачах классификации русскоязычных текстов, в том числе и на данной. Возможно, если требуется скорость работы побольше, стоит использовать статические векторы, например Word2Vec/FastText. TF-IDF для выбранной задачи показался слишком слабым, так как в Twitter часто пишут неологизмами, значения которых BERT из контекста хорошо достаёт.

## Оценки методов

Были выбраны

- Accuracy
- Precision
- Recall

### Модель 1 - BERT Embeddings + SVM

Accuracy: 0.9925
Precision: 0.9924
Recall: 0.9929

### Модель 2 - BERT + linear NN

На тестовом датасете

Accuracy: 0.9998
Precision: 0.9997
Recall: 0.9999

## Выводы

Оба метода отлично отработали, потому что первый использовал сильные признаки, а второй дообучал лучшую для данной задачи нейросетевую модель.

Очень приятно удивлён работой SVM и уж тем более использованной линейной версией. Всё-таки с классическими методами машинного обучения пока не стоит прощаться, потому что на готовых признаках можно получить достаточно хорошее решение быстрее.